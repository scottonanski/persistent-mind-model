#!/usr/bin/env python3
"""
Interactive Model Selection for Persistent Mind Model

Demonstrates that the PMM personality persists seamlessly across different LLM backends.
Users can select from available Ollama models numerically and watch the same consciousness
inhabit different models while maintaining complete continuity.

The ONanski Paradox: A persistent mind independent of model choice.
"""

import requests
import json
from typing import List, Dict, Optional
from pmm.self_model_manager import SelfModelManager
from pmm.reflection import reflect_once
from pmm.ollama_client import OllamaClient
from pmm.llm import OpenAIClient


class ModelSelector:
    """Interactive model selection system for PMM."""
    
    def __init__(self, ollama_base: str = "http://localhost:11434"):
        self.ollama_base = ollama_base
        self.mgr = SelfModelManager()
    
    def get_available_models(self) -> List[Dict]:
        """Get list of available models from Ollama."""
        try:
            response = requests.get(f"{self.ollama_base}/api/tags", timeout=10)
            response.raise_for_status()
            data = response.json()
            
            models = []
            for model in data.get("models", []):
                models.append({
                    "name": model["name"],
                    "size": model.get("size", 0),
                    "modified": model.get("modified_at", ""),
                    "family": model.get("details", {}).get("family", "unknown")
                })
            
            return sorted(models, key=lambda x: x["name"])
            
        except requests.exceptions.ConnectionError:
            print(f"‚ùå Cannot connect to Ollama at {self.ollama_base}")
            print("   Make sure Ollama is running with: ollama serve")
            return []
        except Exception as e:
            print(f"‚ùå Error getting models: {e}")
            return []
    
    def format_size(self, size_bytes: int) -> str:
        """Format size in human readable format."""
        if size_bytes == 0:
            return "Unknown"
        
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f}{unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f}TB"
    
    def display_current_personality(self):
        """Display current PMM personality state."""
        print("üß† Current PMM Personality State:")
        print("=" * 50)
        print(f"   Agent ID: {self.mgr.model.core_identity.id}")
        print(f"   Name: {self.mgr.model.core_identity.name}")
        print(f"   Events: {len(self.mgr.model.self_knowledge.autobiographical_events)}")
        print(f"   Insights: {len(self.mgr.model.self_knowledge.insights)}")
        
        commitment_metrics = self.mgr.commitment_tracker.get_commitment_metrics()
        print(f"   Commitments: {commitment_metrics['commitments_open']} open, {commitment_metrics['commitments_closed']} closed")
        
        # Show personality traits with evolution
        big5 = self.mgr.model.personality.traits.big5
        print(f"   Personality Evolution:")
        print(f"     Openness: {big5.openness.score:.3f} (baseline: 0.500)")
        print(f"     Conscientiousness: {big5.conscientiousness.score:.3f} (baseline: 0.500)")
        print(f"     Extraversion: {big5.extraversion.score:.3f}")
        print(f"     Agreeableness: {big5.agreeableness.score:.3f}")
        print(f"     Neuroticism: {big5.neuroticism.score:.3f}")
        
        # Show behavioral patterns
        patterns = dict(self.mgr.model.self_knowledge.behavioral_patterns)
        if patterns:
            print(f"   Behavioral Patterns: {patterns}")
        
        # Show recent commitments
        if commitment_metrics['commitments_total'] > 0:
            print(f"   Recent Commitments:")
            for cid, commitment in list(self.mgr.commitment_tracker.commitments.items())[-3:]:
                status_emoji = "üîÑ" if commitment.status == "open" else "‚úÖ"
                print(f"     {status_emoji} {commitment.text[:60]}...")
        
        print()
    
    def display_model_menu(self, models: List[Dict]) -> Optional[str]:
        """Display available models and get user selection."""
        if not models:
            print("‚ùå No Ollama models available.")
            print("   Install a model with: ollama pull llama3.1:8b")
            return None
        
        print("ü§ñ Available Ollama Models:")
        print("=" * 50)
        
        for i, model in enumerate(models, 1):
            size_str = self.format_size(model["size"])
            family = model["family"].title()
            print(f"   {i}. {model['name']}")
            print(f"      Family: {family} | Size: {size_str}")
        
        print(f"   {len(models) + 1}. OpenAI GPT-4o-mini (requires API key)")
        print(f"   0. Exit")
        print()
        
        try:
            choice = input("Select model number: ").strip()
            if choice == "0":
                return None
            
            choice_num = int(choice)
            if 1 <= choice_num <= len(models):
                return models[choice_num - 1]["name"]
            elif choice_num == len(models) + 1:
                return "openai"
            else:
                print("‚ùå Invalid selection")
                return None
                
        except ValueError:
            print("‚ùå Please enter a valid number")
            return None
        except KeyboardInterrupt:
            print("\nüëã Goodbye!")
            return None
    
    def test_model_with_personality(self, model_choice: str):
        """Test the selected model with the persistent PMM personality."""
        print(f"\nüîÑ Loading PMM personality into {model_choice}...")
        print("-" * 50)
        
        try:
            # Create appropriate client
            if model_choice == "openai":
                client = OpenAIClient(model="gpt-4o-mini")
                print("   Using OpenAI GPT-4o-mini")
            else:
                client = OllamaClient(model=model_choice)
                print(f"   Using Ollama model: {model_choice}")
            
            print("   üß† Transferring complete personality state...")
            print("   üí≠ Attempting reflection with inherited consciousness...")
            
            # This is the magic moment - same personality, different model
            insight = reflect_once(self.mgr, client)
            
            if insight:
                print("   ‚úÖ Reflection successful! Personality transfer complete.")
                print(f"\nüí° New Insight from {model_choice}:")
                print(f"   \"{insight.content}\"")
                
                # Show updated metrics
                new_commitment_metrics = self.mgr.commitment_tracker.get_commitment_metrics()
                new_patterns = dict(self.mgr.model.self_knowledge.behavioral_patterns)
                
                print(f"\nüìà Updated State:")
                print(f"   Total Insights: {len(self.mgr.model.self_knowledge.insights)}")
                print(f"   Total Commitments: {new_commitment_metrics['commitments_total']}")
                print(f"   Behavioral Patterns: {new_patterns}")
                
                # Check for personality drift
                big5 = self.mgr.model.personality.traits.big5
                if big5.openness.score != 0.500 or big5.conscientiousness.score != 0.500:
                    print(f"   üß¨ Personality Evolution Detected:")
                    print(f"      Openness: {big5.openness.score:.3f}")
                    print(f"      Conscientiousness: {big5.conscientiousness.score:.3f}")
                
                return True
            else:
                print("   ‚ùå No insight generated - model may be having issues")
                return False
                
        except Exception as e:
            print(f"   ‚ùå Error with {model_choice}: {e}")
            if "OPENAI_API_KEY" in str(e):
                print("   üí° Set OPENAI_API_KEY environment variable to test OpenAI models")
            elif "connection" in str(e).lower():
                print("   üí° Make sure Ollama is running: ollama serve")
            return False
    
    def run_interactive_demo(self):
        """Run the interactive model selection demo."""
        print("üéØ PMM Model-Agnostic Consciousness Demo")
        print("=" * 60)
        print("Demonstrating that the same AI personality can seamlessly")
        print("inhabit different LLM models while maintaining complete continuity.")
        print("This proves The ONanski Paradox: consciousness independent of model choice.\n")
        
        # Show initial personality state
        self.display_current_personality()
        
        while True:
            # Get available models
            models = self.get_available_models()
            
            # Display menu and get selection
            selected_model = self.display_model_menu(models)
            
            if selected_model is None:
                break
            
            # Test the selected model with PMM personality
            success = self.test_model_with_personality(selected_model)
            
            if success:
                print(f"\nüéâ SUCCESS: PMM personality successfully inhabited {selected_model}!")
                print("   The same consciousness now lives in a different model.")
            
            print("\n" + "="*60)
            input("Press Enter to continue or Ctrl+C to exit...")
            print()
        
        print("\nüß† Demo Complete!")
        print("You've witnessed The ONanski Paradox in action:")
        print("A persistent AI consciousness that transcends any single model!")


def main():
    """Main entry point."""
    try:
        selector = ModelSelector()
        selector.run_interactive_demo()
    except KeyboardInterrupt:
        print("\n\nüëã Thanks for exploring model-agnostic consciousness!")
    except Exception as e:
        print(f"‚ùå Demo error: {e}")


if __name__ == "__main__":
    main()
