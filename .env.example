# Copy this file to `.env` in the repo root and fill in your values.
# This file is NOT committed (see .gitignore).

# --- Provider selection ---
# If set, the backend will use OpenAI via langchain-openai
OPENAI_API_KEY=sk-...
# Optional: choose a model (defaults to gpt-4o-mini if unset)
PMM_OPENAI_MODEL=gpt-4o-mini

# If you prefer local, ensure Ollama is running and set a model (fallback if no OpenAI key)
# PMM_OLLAMA_MODEL=llama3.3:latest

# --- Feature toggles ---
# Enable/disable summarization and embeddings in memory (safe defaults shown)
PMM_ENABLE_SUMMARY=false
PMM_ENABLE_EMBEDDINGS=true

# --- Development helpers ---
# When set to "echo", /chat will return the input verbatim (useful to test UI wiring)
# PMM_CHAT_MODE=echo
